{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T07:14:16.509418Z",
     "start_time": "2024-07-20T07:14:16.502049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import json"
   ],
   "id": "4084415836826c07",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T07:14:17.380627Z",
     "start_time": "2024-07-20T07:14:17.369509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def needleman_wunsch(seq1, seq2, match=2, mismatch=-1, gap=-1):\n",
    "    n = len(seq1)\n",
    "    m = len(seq2)\n",
    "    score = np.zeros((n+1, m+1))\n",
    "    \n",
    "    for i in range(n+1):\n",
    "        score[i][0] = gap * i\n",
    "    for j in range(m+1):\n",
    "        score[0][j] = gap * j\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            match_score = score[i-1][j-1] + (match if seq1[i-1]['word'] == seq2[j-1]['word'] else mismatch)\n",
    "            delete = score[i-1][j] + gap\n",
    "            insert = score[i][j-1] + gap\n",
    "            score[i][j] = max(match_score, delete, insert)\n",
    "\n",
    "    align1, align2 = [], []\n",
    "    i, j = n, m\n",
    "    while i > 0 or j > 0:\n",
    "        current_score = score[i][j]\n",
    "        if i > 0 and j > 0 and (current_score == score[i-1][j-1] + (match if seq1[i-1]['word'] == seq2[j-1]['word'] else mismatch)):\n",
    "            align1.append(seq1[i-1])\n",
    "            align2.append(seq2[j-1])\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif i > 0 and (current_score == score[i-1][j] + gap):\n",
    "            align1.append(seq1[i-1])\n",
    "            align2.append({'word': '-', 'meta': '-'})\n",
    "            i -= 1\n",
    "        else:\n",
    "            align1.append({'word': '-', 'meta': '-'})\n",
    "            align2.append(seq2[j-1])\n",
    "            j -= 1\n",
    "\n",
    "    return align1[::-1], align2[::-1]"
   ],
   "id": "a9c4e906e1391d95",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T07:14:18.710250Z",
     "start_time": "2024-07-20T07:14:18.706916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_include(start1, end1, start2, end2):\n",
    "    return start1 <= start2 <= end1 or start1 <= end2 <= end1 or (start1 >= start2 and end1 <= end2)"
   ],
   "id": "c9227f8cc23ca855",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "original_json = ['몽구리 귀여워 몽멍멍뭉', '히히 웃으며 뛰어놀지', '해맑은 얼굴 몽구리의 세상', '모두가 웃는 축제의 날', '몽구리 잡아 무야지 호로로로록', '모두 다 함께 즐거운 시간', '몽구리 웃음소리',\n",
    "            '행복이 가득 몽구리와 함께 꿈을 꾸어봐', '몽구리의 하루 밝고 빛나는', '모두의 마음을 따뜻하게', '몽구리 잡아무야지 호로로로록', '모두 다 함께 즐거운 시간']\n",
    "original_dict = []\n",
    "for i, phase in enumerate(original_json):\n",
    "    for word in phase.split():\n",
    "        original_dict.append({'word': word, 'phase': i})\n",
    "\n",
    "with open('data/lyrics.json', 'r') as f:\n",
    "    pred_json = json.load(f)\n",
    "    \n",
    "pred_dict = []\n",
    "for phase in pred_json:\n",
    "    for word in phase['words']:\n",
    "        pred_dict.append(word)"
   ],
   "id": "f1fe1033a0c59c2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T07:41:14.719859Z",
     "start_time": "2024-07-20T07:41:14.707736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "org_align, pred_align = needleman_wunsch(original_dict, pred_dict)\n",
    "pred_bag = []\n",
    "org_bag = []\n",
    "org_result = []\n",
    "for org, pred in zip(org_align, pred_align):\n",
    "    print(org['word'], pred['word'])\n",
    "    if org['word'] == '-':\n",
    "        if pred['word'] != '-':\n",
    "            pred_bag.append(pred)\n",
    "    else:\n",
    "        if pred['word'] == '-':\n",
    "            if len(pred_bag) > 0:\n",
    "                start_time = pred_bag[0]['start']\n",
    "                end_time = pred_bag[-1]['end']\n",
    "            else:  # 뒤에 나올 단어 아니면 앞에 단어와 합칠 것 \n",
    "                org_bag.append(org)\n",
    "                continue\n",
    "        else:\n",
    "            if len(pred_bag) > 0:\n",
    "                start_time = pred_bag[0]['start']\n",
    "            else:\n",
    "                start_time = pred['start']\n",
    "            end_time = pred['end']\n",
    "        \n",
    "        if len(org_bag) > 0:\n",
    "            for missed_org in org_bag:\n",
    "                if missed_org['phase'] == org['phase']:\n",
    "                    org['word'] = missed_org['word'] + org['word']\n",
    "                else:\n",
    "                    org_result[-1]['word'] = org_result[-1]['word'] + missed_org['word']\n",
    "            org_bag = []\n",
    "        org_result.append({'word': org['word'], 'start': start_time, 'end': end_time, 'phase': org['phase']})\n",
    "            \n",
    "        pred_bag = []\n",
    "\n",
    "print(org_result)"
   ],
   "id": "4578ef7f1c26bab5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 모두\n",
      "- 모두\n",
      "몽구리 우리\n",
      "귀여워 귀여워\n",
      "몽멍멍뭉 너무너무\n",
      "히히 히히\n",
      "웃으며 웃으며\n",
      "뛰어놀지 뛰어놀지\n",
      "해맑은 흐르는\n",
      "얼굴 얼굴\n",
      "몽구리의 눈구리에\n",
      "세상 쏜\n",
      "모두가 모두가\n",
      "웃는 웃는\n",
      "축제의 축제의\n",
      "날 날\n",
      "몽구리 몽글이\n",
      "잡아 잡아\n",
      "무야지 놓야지\n",
      "호로로로록 호로로로록\n",
      "모두 모두\n",
      "다 다\n",
      "함께 함께\n",
      "즐거운 즐거운\n",
      "시간 시간\n",
      "몽구리 몽구리\n",
      "웃음소리 웃음소리\n",
      "행복이 행복이\n",
      "가득 가득\n",
      "몽구리와 몽구리와\n",
      "함께 함께\n",
      "꿈을 꿈을\n",
      "꾸어봐 꾸어본\n",
      "몽구리의 몽구리의\n",
      "하루 하루\n",
      "밝고 밝고\n",
      "빛나는 빛나는\n",
      "모두의 모두의\n",
      "마음을 마음을\n",
      "따뜻하게 따뜻하게\n",
      "몽구리 몽구리\n",
      "- 잡아\n",
      "잡아무야지 놓아야지\n",
      "호로로로록 호로로로록\n",
      "모두 -\n",
      "다 모두가\n",
      "함께 함께\n",
      "즐거운 즐거운\n",
      "시간 시간\n",
      "[{'word': '몽구리', 'start': 9.02578231292517, 'end': 10.62312925170068, 'phase': 0}, {'word': '귀여워', 'start': 10.62795918367347, 'end': 11.493877551020407, 'phase': 0}, {'word': '몽멍멍뭉', 'start': 11.498707482993197, 'end': 14.001632653061224, 'phase': 0}, {'word': '히히', 'start': 14.110952380952382, 'end': 14.872380952380952, 'phase': 1}, {'word': '웃으며', 'start': 14.94687074829932, 'end': 16.02176870748299, 'phase': 1}, {'word': '뛰어놀지', 'start': 16.06142857142857, 'end': 16.92734693877551, 'phase': 1}, {'word': '해맑은', 'start': 16.932176870748297, 'end': 19.435102040816325, 'phase': 2}, {'word': '얼굴', 'start': 19.509591836734693, 'end': 20.584489795918365, 'phase': 2}, {'word': '몽구리의', 'start': 20.624149659863942, 'end': 21.733877551020406, 'phase': 2}, {'word': '세상', 'start': 22.052176870748298, 'end': 23.12707482993197, 'phase': 2}, {'word': '모두가', 'start': 23.201564625850338, 'end': 24.624761904761904, 'phase': 3}, {'word': '웃는', 'start': 24.69925170068027, 'end': 25.18204081632653, 'phase': 3}, {'word': '축제의', 'start': 25.291360544217685, 'end': 26.29659863945578, 'phase': 3}, {'word': '날', 'start': 26.475578231292516, 'end': 27.132517006802722, 'phase': 3}, {'word': '몽구리', 'start': 27.1721768707483, 'end': 28.31673469387755, 'phase': 4}, {'word': '잡아', 'start': 28.32156462585034, 'end': 28.908843537414967, 'phase': 4}, {'word': '무야지', 'start': 28.913673469387753, 'end': 29.361632653061225, 'phase': 4}, {'word': '호로로로록', 'start': 29.4012925170068, 'end': 31.730068027210883, 'phase': 4}, {'word': '모두', 'start': 31.76972789115646, 'end': 32.35700680272109, 'phase': 5}, {'word': '다', 'start': 32.361836734693874, 'end': 32.879455782312924, 'phase': 5}, {'word': '함께', 'start': 32.919115646258504, 'end': 33.50639455782313, 'phase': 5}, {'word': '즐거운', 'start': 33.511224489795914, 'end': 34.34231292517007, 'phase': 5}, {'word': '시간', 'start': 34.38197278911564, 'end': 36.067, 'phase': 5}, {'word': '몽구리', 'start': 45.492721088435374, 'end': 47.438367346938776, 'phase': 6}, {'word': '웃음소리', 'start': 47.54768707482993, 'end': 49.73714285714286, 'phase': 6}, {'word': '행복이', 'start': 49.77680272108843, 'end': 50.607891156462586, 'phase': 7}, {'word': '가득', 'start': 50.61272108843537, 'end': 51.11272108843537, 'phase': 7}, {'word': '몽구리와', 'start': 52.005918367346936, 'end': 52.628027210884355, 'phase': 7}, {'word': '함께', 'start': 52.63285714285714, 'end': 52.906666666666666, 'phase': 7}, {'word': '꿈을', 'start': 52.91149659863945, 'end': 53.46394557823129, 'phase': 7}, {'word': '꾸어봐', 'start': 53.50360544217687, 'end': 54.00360544217687, 'phase': 7}, {'word': '몽구리의', 'start': 55.488911564625845, 'end': 56.563809523809525, 'phase': 8}, {'word': '하루', 'start': 56.638299319727885, 'end': 57.155918367346935, 'phase': 8}, {'word': '밝고', 'start': 57.195578231292515, 'end': 57.713197278911565, 'phase': 8}, {'word': '빛나는', 'start': 57.961836734693875, 'end': 58.461836734693875, 'phase': 8}, {'word': '모두의', 'start': 60.01680272108843, 'end': 60.882721088435375, 'phase': 9}, {'word': '마음을', 'start': 60.88755102040816, 'end': 61.7534693877551, 'phase': 9}, {'word': '따뜻하게', 'start': 62.07176870748299, 'end': 62.57176870748299, 'phase': 9}, {'word': '몽구리', 'start': 63.743605442176865, 'end': 64.92299319727891, 'phase': 10}, {'word': '잡아무야지', 'start': 64.92782312925169, 'end': 65.72408163265305, 'phase': 10}, {'word': '호로로로록', 'start': 65.76374149659864, 'end': 66.26374149659864, 'phase': 10}, {'word': '모두다', 'start': 68.34115646258503, 'end': 69.4508843537415, 'phase': 11}, {'word': '함께', 'start': 69.49054421768707, 'end': 70.0778231292517, 'phase': 11}, {'word': '즐거운', 'start': 70.08265306122449, 'end': 70.87891156462585, 'phase': 11}, {'word': '시간', 'start': 70.91857142857143, 'end': 71.41857142857143, 'phase': 11}]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:05:40.429715Z",
     "start_time": "2024-07-21T12:05:40.382862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_lyrics = \"[Verse]\\nStrings in motion\\nBrass resounding loud\\nThe Maestro stands tall\\nCommanding the crowd\\nHis baton sweeps\\nThe notes take flight\\nEuphonic waves fill the starry night\\n\\nMelodies entwine\\nHarmonies unfold\\nHis hands\\nLike magic\\nTurn silver to gold\\nThe orchestra plays\\nIn perfect accord\\nA symphony of beauty\\nNone can afford\\n\\n[Verse 2]\\nWith each precise movement\\nThe music swells\\nThe Maestro's passion\\nNo one can quell\\nHis eyes ablaze\\nWith musical fire\\nIgniting souls\\nTaking them higher\"\n",
    "t = [lyric for lyric in test_lyrics.split('\\n') if not lyric.startswith('[') and not lyric.endswith(']')]\n",
    "for i, phase in enumerate(t):\n",
    "    for word in phase.split():\n",
    "        print(word, i)"
   ],
   "id": "85efb3e0b25ad7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strings 0\n",
      "in 0\n",
      "motion 0\n",
      "Brass 1\n",
      "resounding 1\n",
      "loud 1\n",
      "The 2\n",
      "Maestro 2\n",
      "stands 2\n",
      "tall 2\n",
      "Commanding 3\n",
      "the 3\n",
      "crowd 3\n",
      "His 4\n",
      "baton 4\n",
      "sweeps 4\n",
      "The 5\n",
      "notes 5\n",
      "take 5\n",
      "flight 5\n",
      "Euphonic 6\n",
      "waves 6\n",
      "fill 6\n",
      "the 6\n",
      "starry 6\n",
      "night 6\n",
      "Melodies 8\n",
      "entwine 8\n",
      "Harmonies 9\n",
      "unfold 9\n",
      "His 10\n",
      "hands 10\n",
      "Like 11\n",
      "magic 11\n",
      "Turn 12\n",
      "silver 12\n",
      "to 12\n",
      "gold 12\n",
      "The 13\n",
      "orchestra 13\n",
      "plays 13\n",
      "In 14\n",
      "perfect 14\n",
      "accord 14\n",
      "A 15\n",
      "symphony 15\n",
      "of 15\n",
      "beauty 15\n",
      "None 16\n",
      "can 16\n",
      "afford 16\n",
      "With 18\n",
      "each 18\n",
      "precise 18\n",
      "movement 18\n",
      "The 19\n",
      "music 19\n",
      "swells 19\n",
      "The 20\n",
      "Maestro's 20\n",
      "passion 20\n",
      "No 21\n",
      "one 21\n",
      "can 21\n",
      "quell 21\n",
      "His 22\n",
      "eyes 22\n",
      "ablaze 22\n",
      "With 23\n",
      "musical 23\n",
      "fire 23\n",
      "Igniting 24\n",
      "souls 24\n",
      "Taking 25\n",
      "them 25\n",
      "higher 25\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T07:16:18.113341Z",
     "start_time": "2024-07-23T07:16:18.044100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import madmom\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def normalize_amplitude(amplitudes):\n",
    "    \"\"\"\n",
    "    Normalize the amplitude values to the range [0, 1].\n",
    "    \"\"\"\n",
    "    min_amp = np.min(amplitudes)\n",
    "    max_amp = np.max(amplitudes)\n",
    "    return (amplitudes - min_amp) / (max_amp - min_amp) if max_amp > min_amp else amplitudes\n",
    "\n",
    "def get_beat_amplitudes(audio_file):\n",
    "    # Load audio file with Librosa\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "    # Use Madmom to detect beats\n",
    "    proc = madmom.features.beats.RNNBeatProcessor()\n",
    "    act = proc(audio_file)\n",
    "    beats = madmom.features.beats.DBNBeatTrackingProcessor(fps=100)(act)\n",
    "\n",
    "    # Convert beat times to sample indices\n",
    "    beat_samples = librosa.time_to_samples(beats, sr=sr)\n",
    "\n",
    "    # Extract amplitudes at beat times\n",
    "    beat_amplitudes = y[beat_samples]\n",
    "\n",
    "    # Normalize amplitudes to range [0, 1]\n",
    "    normalized_amplitudes = normalize_amplitude(beat_amplitudes)\n",
    "\n",
    "    return y, sr, beats, normalized_amplitudes\n",
    "\n",
    "def plot_beat_amplitudes(audio_file):\n",
    "    # Get audio data and beat information\n",
    "    y, sr, beats, normalized_amplitudes = get_beat_amplitudes(audio_file)\n",
    "\n",
    "    # Generate time axis for the audio signal\n",
    "    time = np.arange(len(y)) / sr\n",
    "\n",
    "    # Plot the audio waveform\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(time, y, label='Audio Waveform')\n",
    "    plt.scatter(beats, y[librosa.time_to_samples(beats, sr=sr)], color='r', marker='o', label='Beats')\n",
    "    plt.title('Audio Waveform with Beat Markers')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot normalized amplitudes at beats\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.stem(beats, normalized_amplitudes, basefmt=\" \")\n",
    "    plt.title('Normalized Amplitudes at Beats')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Normalized Amplitude')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    for beat, amp in zip(beats, normalized_amplitudes):\n",
    "        print(beat, amp)"
   ],
   "id": "6cb5b7c2ecb06025",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_beat_amplitudes('data/music.wav')",
   "id": "d6bd6572fda96f0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T13:12:11.125077Z",
     "start_time": "2024-07-26T13:11:59.555635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import whisperx\n",
    "import gc"
   ],
   "id": "27b6267c0c49cc82",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[14013]: Class AVFFrameReceiver is implemented in both /usr/local/Cellar/ffmpeg/6.0_2/lib/libavdevice.60.1.100.dylib (0x1296ed378) and /Users/supermoon/projects/musicAnalyzeServer/.venv/lib/python3.12/site-packages/av/.dylibs/libavdevice.60.1.100.dylib (0x136f640f8). One of the two will be used. Which one is undefined.\n",
      "objc[14013]: Class AVFAudioReceiver is implemented in both /usr/local/Cellar/ffmpeg/6.0_2/lib/libavdevice.60.1.100.dylib (0x1296ed3c8) and /Users/supermoon/projects/musicAnalyzeServer/.venv/lib/python3.12/site-packages/av/.dylibs/libavdevice.60.1.100.dylib (0x136f64148). One of the two will be used. Which one is undefined.\n",
      "/Users/supermoon/projects/musicAnalyzeServer/.venv/lib/python3.12/site-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "torchvision is not available - cannot save figures\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-26T13:12:31.441712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cpu\" \n",
    "audio_file = \"data/music.wav\"\n",
    "batch_size = 16 # reduce if low on GPU mem\n",
    "compute_type = \"int8\" # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "\n",
    "# 1. Transcribe with original whisper (batched)\n",
    "model = whisperx.load_model(\"base\", device, compute_type=compute_type)\n",
    "\n",
    "# save model to local path (optional)\n",
    "# model_dir = \"/path/\"\n",
    "# model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type, download_root=model_dir)\n",
    "\n",
    "audio = whisperx.load_audio(audio_file)\n",
    "print(f'audio: {audio_file}')\n",
    "result = model.transcribe(audio, batch_size=batch_size, language='korean')\n",
    "print(result[\"segments\"]) # before alignment\n",
    "\n",
    "# delete model if low on GPU resources\n",
    "# import gc; gc.collect(); torch.cuda.empty_cache(); del model\n",
    "\n",
    "# 2. Align whisper output\n",
    "model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
    "result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=True)\n",
    "\n",
    "print(result[\"segments\"]) # after alignment\n",
    "\n",
    "# delete model if low on GPU resources\n",
    "# import gc; gc.collect(); torch.cuda.empty_cache(); del model_a\n",
    "\n",
    "# 3. Assign speaker labels\n",
    "diarize_model = whisperx.DiarizationPipeline(use_auth_token='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', device=device)\n",
    "\n",
    "# add min/max number of speakers if known\n",
    "diarize_segments = diarize_model(audio)\n",
    "# diarize_model(audio, min_speakers=min_speakers, max_speakers=max_speakers)\n",
    "\n",
    "result = whisperx.assign_word_speakers(diarize_segments, result)\n",
    "print(diarize_segments)\n",
    "print(result[\"segments\"]) # segments are now assigned speaker IDs"
   ],
   "id": "ac8d65e116baaaf7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/torch/whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.2.2. Bad things might happen unless you revert torch to 1.x.\n",
      "audio: data/music.wav\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
